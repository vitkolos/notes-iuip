# Exam

## Motion Planning, Navigation

- motion planning
	- global map, off-line, strategic resoning
	- motion optimality
	- convergence to the goal
	- no reactivity
- reactive & end-to-end navigation
	- local sensor map, on-line, tactical reasoning
	- motion optimality?
	- convergence to the goal?
	- reactivity

### Workspace, Configuration Space

- motion planning
	- feasible plan = takes the capabilities of the robot into account
	- motion strategies can have different forms – it can be a path, a set of procedural instructions
	- for a walking humanoid robot, the plan would be quite complex
- motion planning vs. navigation (obstacle avoidance etc.)
	- motion planning – global map, strategic level
	- obstacle avoidance – local map, tactical level
- workspace
	- physical space where the robot lives, usually $\mathbb R^2$ or $\mathbb R^3$
	- obstacles, free space
	- types of models
		- continuous metric model
			- polygons – their vertices
			- memory complexity proportional to the number of obstacles
		- discrete metric model
			- pixels: free, fully occupied, partially occupied
			- memory complexity proportional to the size of workspace and the resolution
		- topological model
			- nodes and edges
			- we don't care about the geometry – we only capture places and ways to move from one to another
			- the robot needs to be able to localize itself (what is the current “place”) and to get from one place to another according to the edges in the graph
		- hybrid
	- selection criteria: sensors available, precision required, complexity (memory requirements)
- two classes of kinematic constraints
	- holonomic – restrict the set of possible position (like obstacles)
		- examples
			- limitations of the robotic arm due to its joints etc.
			- robotic hand with glass of water has to be upright – we limit the hand to some angles
		- to account for the constraints, we only add some virtual obstacles
	- nonholonomic – restrict the set of possible differential motions
		- example: a wheel rolling without slipping on the plane (you should move in a direction perpendicular to the axis of the wheel)
- **configuration**
	- fundamental tool to address motion planning
	- *set of independent parameters uniquely specifying the position and orientation of every component of a robotic system relative to a fixed coordinate system*
	- usually expressed as a vector of positions/orientations
	- configuration space = space of all the configuration
	- example: polygonal robot which can only translate (no rotation)
		- we pick a reference point $R$
		- $q=(q_x,q_y)$ … configuration (coordinates of $R$)
		- $C=\mathbb R^2$ … configuration space
		- $W=\mathbb R^2$ … workspace
	- example: robot which can also rotate
		- $q=(q_x,q_y,\theta)$
		- $C=\mathbb R^2\times S^1$
			- $S^1$ … $[0,2\pi[$ (to some extent)
				- we could also use $[-\pi,\pi[$ or something similar
	- example: free-flying robot in 3D
		- $q=(q_x,q_y,q_z,\theta_\alpha,\theta_\beta,\theta_\gamma)$
		- Euler angles (roll, pitch, yaw)
	- example: robotic arm with two joints
		- $q=(\theta_1,\theta_2)$
		- $C=S^2$
	- example: mobile robot (car) with an arm with two joints
		- $q=(x,y,\theta,\theta_1,\theta_2)$
- configuration space vs. workspace
	- example: robotic arm with two joints
		- base of the robot can be put anywhere → workspace … $\mathbb R^2$
		- $C=S^2$ is bounded
		- $S^2$ topology = sphere
		- but we cannot uniquely convert the top of the sphere to two angles → we need to use a torus
		- $C=S^1\times S^1$
	- what is the shortest path between two configurations in $S^1\times S^1$?
		- in Cartesian space, it would be easy
		- we need a metric
- configuration space path
	- path $\pi:[0,1]\to C$ … continuous sequence of configurations
	- trajectory … time-parametrized path
- configuration types
	- free, collision, contact
	- contact configurations are interesting if you want to pick up something with a robotic arm
	- image of an obstacle in a $C$ space becomes much more complicated
		- we need to capture the structure of the workspace, compute forbidden regions
	- in the workspace, the robot is a body × in the configuration space, the robot is a point

### Path Planning

 - path planning
	 - input
		 - robot model (configuration space)
		 - start, goal (configurations)
		 - workspace model (obstacles, …)
	- output – path
- completeness issue
	- complete algorithm: finds a solution if one exists, reports failure if not
	- complexity of complete path planning: strong evidence that it takes time exponential in $d$, the dimension of the configuration space $C$
	- specific complete path planning algorithms have been implemented for $d=$ 2, 3, or 4
	- two complete general purpose path planning algorithms have been proposed, none has been implemented
- algorithms
	- complete … finds a solution
	- heuristic … finds a solution in most cases
	- probabilistic completeness … probability of finding a solution approaches 1 if given enough time
	- resolution completeness … complete for a given resolution level
- usual methods
	- exploring a search graph
	- incrementally building a search tree

#### Graph-Based Methods

- visibility graph
	- topology of (semifree) C space is described using a network of 1D curves
	- we connect start and goal to the network, then use graph search
	- finds shortest path in 2D space (but not in 3D space)
- Voronoï diagram
	- paths maximizing the clearance to the obstacles
	- mostly in 2D spaces
- cellular decomposition
	- trapezoidal decomposition
		- how to move from one cell to another? we could use the centroids of the shared sides
		- cannot be used if we don't have polygonal obstacles
			- typical problem if the C space is torus
	- approximate cellular decomposition
		- discretize the C space
		- remove the occupied and partially occupied cells
		- problems: narrow passage
	- hierarchical cellular decomposition
		- highly depends on the dimensionality of the C space – the memory requirements grow exponentially
- probabilistic roadmap
	- it's difficult to compute C space obstacles
	- it's easy to check if a configuration collides or not
		- also, we can easily check if a line segment collides or not
	- we randomly sample points, check if they collide and if the lines connecting them collide
	- this way, we form a network
	- the algorithm is probabilistically complete
	- very useful for C space of high dimensionality (like 97 dimensions)

#### Tree-Based Methods

- grid-based methods
	- configuration-space lattices
	- A*
	- bi-directional search
		- is somehow better
- rapidly-exploring random tree
	- algorithm
		- we have a tree
		- sample a configuration in the whole space
		- find the closest node of the tree
		- extend the tree by $\varepsilon$ distance in the direction of the new configuration (if such path is collision-free)
	- Brownian motion explores circle/sphere
		- RRT works better
		- RRT is naturally biased towards large unexplored regions
	- probabilistic completeness
	- we need a metric
#### Other Methods

- navigation function
	- “feedback motion planning”
	- navigation function should be smooth, should have global minimum at the goal and no other local minima
	- gradient descent
- potential field
	- obstacle … repulsive field
	- goal … attractive field
	- robot … particle, subject to forces
	- there can be multiple local minima :(
		- how to avoid getting stuck in a local minimum
		- we can use “basin of attraction”
		- or we can try to move randomly out of the basin
- path deformation
	- start from the original path and deform it until it becomes collision-free
	- ill-suited for dynamic environments
	- space deformation × time deformation

#### Nonholonomic Constraints

- non integrable
- example in $R^2\times S^1$
	- $\dot x\sin\theta-\dot y\cos\theta=\theta$
	- “the wheel has to always move in this direction”
- nonholonomic system: the dimension of the control space is less than the dimension of the configuration space
- controllability
	- locally controllable system
	- small-time locally controllable system
- steering
	- no general method
	- we can use circles for a car
- untractable problem, we need to decouple geometric and kinematic constraints
- topological property
	- the space we need to maneuver
	- we want to get from the middle of the blue circle to every point in the blue circle
	- to get there, we may need to exist the blue circle but we always stay in the pink circle
- using topological property
	- we have a geometrically feasible path
	- we find the largest pink circle that does not collide with any obstacles on the path
	- from the size of the pink circle, we compute the blue circle and “tile” the path using blue circles
- Reeds & Shepp optimal paths
- steering method – verifying the topological property
- holonomic path approximation
- we apply postprocessing to remove weird parts of the path
- graph-based nonholonomic planner
	- we use PRM, but connect the points using the steering method
- can we change RRT to use it to plan paths for cars?
	- yes, but the epsilon advancement has to be feasible – so we can use the steering method or choose from all the possible epsilon advancements the closest one to the sampled point

### Obstacle Avoidance

- reactive navigation (curve in the C space connecting A and B)
	- robot model
	- local map (sensor data)
	- nominal motion/goal
- bug 1 (Lumelski 86)
	- algorithm
		- robot moves to goal until obstacle
		- fully circumnavigate obstacle
		- circumnavigate again to boundary closest to the goal
		- repeat until goal is reached
	- low memory requirements
	- path can be very long
	- converges to the goal
- bug 2
	- we use a line towards the goal
	- convergency does not directly follow from the algorithm
- potential field
	- handling local minima – random motion
- vector field histogram
	- occupancy probability (in a grid)
	- detect candidate openings & select the best one (depending on the target direction and the robot heading)
- dynamic window
	- translational and rotational velocities
	- takes into account the acceleration capabilities of the robot
- velocity obstacles
	- takes into account moving obstacles
- end-to-end navigation
	- we don't separate perception, localization, planning, and control
	- instead, the robot learns a mapping between sensor data and actions
	- supervised learning – ALVINN
	- reinforcement learning
		- policy learned through trial-and-error
		- training in simulation
		- dynamic programming, monte carlo, Q-learning, SARSA, DDPG, …
	- LLM-based navigation
		- GPT-driver
	- how to combine end-to-end techniques with the more robust ones?
		- safety filters?

### Safety

- we'll focus on misreasoning in dynamic environments (one of the causes of collisions)
	- can motion safety be guaranteed?
- in dynamic environments
	- we reason about the future
	- we are limited by the decision time
	- appropriate time horizon – how far do we look in the future?
- inevitable collision states (ICS)
	- “I will be in collision in the future no matter what I do”
	- we need to stay away from ICS
	- obstacles are not independent!
	- in general, we need an infinite time horizon
- the time horizon and the decision time are determined by the environment
	- if the time horizon is infinite, we cannot guarantee absolute motion safety
- modeling the future (forbidden regions)
	- deterministic – we know where the obstacles end up
	- conservative – are not sure, so we let the forbidden regions grow
		- problem: if they grow infinitely → no collision-free path in the future (with an infinite time horizon)
	- probabilistic
		- no obstacles in the far future
- passive motion safety
	- should a collision take place, the robot will be at rest
	- now, we don't need an infinite time horizon
	- everybody enforces it → no collision at all

## Kinematics

- exercises
	- describe the position of the points $P_1,P_2$ on the robotic arm as functions of the angles $q_1,q_2$
		- so we get $\begin{bmatrix} x_1 \\ y_1 \end{bmatrix}$ and $\begin{bmatrix} x_2 \\ y_2 \end{bmatrix}$
	- write $\begin{bmatrix}\dot x_2 \\ \dot y_2 \end{bmatrix}$
	- then, express this as a multiplication of a matrix and a vector (Jacobian matrix)
	- how to get $\dot q_1,\dot q_2$ if we know $\dot x_2,\dot y_2$?
		- we need an inverse of the Jacobian matrix
	- is there an inverse of the Jacobian matrix?
		- if not, why? (when yes, when no?)
			- fully extended, fully flexed
		- 2×2 matrix → determinant = $ad-bc$
		- using sin/cos formulas
	- kinetic energy of a robot
		- $K=\frac12m_1v_1^2+\frac12m_2v_2^2$
			- if we consider two point masses
			- then $v_1^2=\begin{bmatrix}\dot x_1 \\ \dot y_1 \end{bmatrix}^T\begin{bmatrix}\dot x_1 \\ \dot y_1 \end{bmatrix}$
		- we want to get to $K=\frac 12\dot q^T M(q)\dot q$
			- we need Jacobians
			- for two point masses, we can get $K=\frac12 m_1\dot q^TJ_1^TJ_1\dot q+\frac12 m_2\dot q^TJ_2^TJ_2\dot q$
				- we may want to modify the expression so that $K=\frac12\dot q^T(m_1J_1^TJ_1+m_2J_2^TJ_2)\dot q$
				- then $M(q)=m_1J_1^TJ_1+m_2J_2^TJ_2$

## Estimation Techniques

*work in progress*

### State Estimation

- we estimate the state (several physical quantities) of the robot
	- e.g. localization
		- 3 dimensions in 2D (x, y, angle)
		- 6 dimensions in 3D
	- based on measurements (sensors)
	- in general, the sensors don't directly provide the components of the state
	- usually, there is also some noise
- classes of sensors
	- related to the evolution of the state
		- e.g. encoder on the wheels
		- $S_i=f(S_{i-1},u_i)$
			- $S_i$ … state at time $i$
			- $u_i$ … measurement at time $i$
		- *proprioceptive sensor*
	- related only to the current state at a given time
		- $z_i=h(S_i)$
			- $z_i$ … measurement at time $i$
		- *exteroceptive sensor*
- synchronous drive: free-moving robot with three synchronous wheels (just like a single moving wheel, it can rotate and move forwards/backwards)
	- $u_i=(\delta\rho_i,\delta\theta_i)$
	- $S=(x,y,\theta)$
	- actions of rotation and move are not commutative w.r.t. position
		- we end up at a different position if we first move and then rotate
		- but we can assume that the sampling is very fast
	- we can define $f$ like this
		- $x_i=x_{i-1}+\delta\rho_{i-1}\cos\theta_{i-1}$
		- $y_i=y_{i-1}+\delta\rho_{i-1}\sin\theta_{i-1}$
		- $\theta_i=\theta_{i-1}+\delta\theta_i$
- differential drive
	- $u_i=(\alpha^R_i,\alpha^L_i)$
	- $r^R,r^L$ … radii of wheels
	- shift: $s^R=r^R\alpha^R$ (similar for $s^L$)
	- $\delta\rho=\frac{s^R+s^L}2$
	- $\delta\theta=\frac{s^R-s^L}{b}$
- examples of $h$
	- if we measure the distance from origin
		- $z=h(S)=\sqrt{x^2+y^2}$
- we try to find (and update) a probability distribution
	- we start with a uniform distribution
	- how to update it to reflect the new measurements?

### Bayes Filter

- total probability
	- $P(A)=\sum_B P(A,B)$
	- $P(A\mid C)=\int dB\;P(A\mid B,C)P(B\mid C)$
- Bayes law
	- $P(A\mid B)=\frac{P(B\mid A)P(A)}{P(B)}$
	- $P(A\mid B,C)=\frac{P(B\mid A,C)P(A\mid C)}{P(B\mid C)}$
- $U_i=[u_0,u_1,\dots,u_{i-1},u_i]$
- $Z_i=[z_0,z_1,\dots,z_{i-1},z_i]$
- we start with $P(S_{i-1}\mid U_{i-1}Z_{i-1})$
- *action* leads to $P(S_{i}\mid U_{i}Z_{i-1})$
	- it adds $u_i$
- *perception* leads to $P(S_{i}\mid U_{i}Z_{i})$
	- it adds $z_i$
- clearly $P(S_i\mid U_iZ_{i-1})=\int dS_{i-1}\;P(S_i\mid S_{i-1},U_iZ_{i-1})P(S_{i-1}\mid U_iZ_{i-1})$
	- where $P(S_{i-1}\mid U_iZ_{i-1})=P(S_{i-1}\mid U_{i-1}Z_{i-1})$ as the previous state is independent on the next measurement
	- by Markov assumption, $P(S_i\mid S_{i-1},U_iZ_{i-1})=P(S_i\mid S_{i-1},u_i)$
		- it's an approximation (in reality, for example, the error of the sensor may be influenced by the past measurements)
	- so we get $P(S_i\mid U_i Z_{i-1})=\int dS_{i-1}\;P(S_i\mid S_{i-1},u_i)P(S_{i-1}\mid U_{i-1}Z_{i-1})$
- $P(S_i\mid z_i,U_i Z_{i-1})=\frac{P(z_i\mid S_i,U_iZ_{i-1})P(S_i\mid U_iZ_{i-1})}{P(z_i\mid U_iZ_{i-1})}$
	- so $P(S_i\mid U_i Z_{i})=\eta P(z_i\mid S_i) P(S_i\mid U_i Z_{i-1})$
	- $\eta$ … normalization factor
- example: exteroceptive sensor
	- $h(x)=L-x=h(S)$
	- let's consider Gaussian
	- $z^m=N(z,\sigma^2)$
		- $z^m$ … measured
		- $z$ … true
	- $z^m=N(L-x,\sigma^2)$
	- $P(z\mid S)=N(L-x,\sigma^2)$
- example: proprioceptive sensor
	- $x_i=x_{i-1}+R\alpha$
	- $\alpha=N(\alpha^m,\sigma_\alpha^2)$
	- $x_i=N(x_{i-1}+R\alpha^m,R^2\sigma_\alpha^2)$
- in reality: trade-off between precision and computational cost (time)
- example
	- we define initial $P(L)$
		- $P(3)=0.2$
		- $P(4)=P(8)=0.4$
		- otherwise, $P(L)=0$
	- $P(L'\mid u)=\sum_L P(L'\mid L,u)P(L)$
		- $u$ … observed shift
		- we can define $P(L'\mid L,u)=\begin{cases}1&\text{if }L'=L+u\\0&\text{otherwise}\end{cases}$
		- more realistic definition
			- 0.8 if $L'=L+u$
			- 0.1 if $L'=L+u\pm 1$
	- $P(L'\mid z)=\eta P(z\mid L')P(L')$
		- again, we have $P(z\mid L')$ defined somehow
		- we also have $P(L')$
		- we need to get $\eta$ by computing $P(z\mid L)P(L)$ for every $L$ and making sure $P(L'\mid z)$ sums to 1
			- in other words, $\eta=\frac1{\sum_{L} P(z\mid L)P(L)}$

### Extended Kalman Filter

- sometimes, we can assume that the functions are linear and the (error) distributions are Gaussian
	- then, everything is Gaussian (we get convolution of two Gaussians which is a Gaussian)
	- we only need mean (vector) and variance (covariance matrix – symmetric and positive semi-definite)
	- → Kalman filter
	- if the assumptions don't hold, we may use a heuristic solution (extended Kalman filter)
- reminder (simplified)
	- $P(S_i\mid U_i)=\int dS_{i-1}\; P(S_i\mid S_{i-1}u_i)P(S_{i-1})$ … action
	- $P(S_i\mid Z_i)=\eta P(z_i\mid S_i)P(S_i)$ … perception
- let's say $x$ is a random variable with Gaussian distribution
	- $x=N(\mu,\sigma^2)$
	- $P(x)=\frac1{\sqrt{2\pi\sigma^2}}\exp(-\frac12\frac{(x-\mu)^2}{\sigma^2})$
	- mean value $\braket{x}=\int_{-\infty}^\infty dx\; xP(x)$
	- variance $\braket{(x-\braket{x})^2}$
- let's consider $P(x_1,x_2)$
	- covariance matrix
- vector case
	- mean vector $\mu$
	- covariance matrix $P$
	- before … $\mu_b,P_b$
	- after … $\mu_a,P_a$
- we need to approximate a non-linear function with a linear function
	- $g(x)\approx g(x_0)+\frac{dg}{dx}\bigg\vert_{x_0}(x-x_0)$
	- so $f(S_{i-1},U_i)=f(\mu_b,u^m)+\frac{\partial f}{\partial S}\bigg\vert_{\mu_b,u^m} (S_{i-1}-\mu_b)+\frac{\partial f}{\partial U}\bigg\vert_{\mu_b,u^m} (U_i-u^m)$
- extended Kalman filter (EKF) prediction
	- $\mu_a=f(\mu_b,u^m)$
	- $P_a=F_xP_bF_x^T+F_uQF_u^T$
	- $Q$ … covariance of the noise of the measurement
- example: wheel
	- $x_i=x_{i-1}+R\alpha_i$
	- $f(S,u)=S+Ru$
	- $\mu_a=\mu_b+R\alpha^m$
	- $F_x=1$
	- $F_u=R$
	- $P_a=\sigma^2_a=\sigma^2_b+R^2\sigma_q^2$
- example: differential drive
	- we have
		- $\delta\rho=\frac{s^R+s^L}2$
		- $\delta\theta=\frac{s^R-s^L}{b}$
		- $f(S,u)=\begin{bmatrix}x+\delta\rho\cos\theta\\ y+\delta\rho\sin\theta \\ \theta+\delta\theta\end{bmatrix}$
		- so $f(S,u)=\begin{bmatrix}x+\frac{s^R+s^L}2\cos\theta\\ y+\frac{s^R+s^L}2\sin\theta \\ \theta+\frac{s^R-s^L}{b}\end{bmatrix}$
	- $F_x$ … Jacobian of $f$ w.r.t. $(x,y,\theta)$
	- $F_u$ … Jacobian of $f$ w.r.t. $(s^R,s^L)$
	- $Q$ … covariance for $(s^R,s^L)$
- after an exteroceptive measurement
	- $\mu_a=\mu_b+P_bH^T[HP_bH^T+R]^{-1}(z^m-h(\mu_b))$
	- $P_a=P_b-P_bH^T[HP_bH^T+R]^{-1}HP_b$
	- $R$ … noise on the vector $z$ (measurement)
	- $h(\mu_b)$ … predicted observation
	- $z^m-h(\mu_b)$ … innovation
- example
	- $h(x)=\mathrm{atan}(\frac{L_y}{L_x-x})$
	- $H=\frac{\partial h}{\partial x}\bigg\vert_{\mu_b}$ … a number
- example: GPS
	- $S=(x,y,\theta)$
	- $h(S)=\begin{bmatrix}x\\ y\end{bmatrix}$
	- $H=\begin{bmatrix}1&0&0\\ 0&1&0\end{bmatrix}$
	- $R=\begin{bmatrix}\sigma_1^2&0\\ 0&\sigma_2^2\end{bmatrix}$
		- if we (wrongly) assume the errors are independent
- example: compass
	- $h(S)=\theta$
	- $H=[0,0,1]$
- example
	- $h(S)=\begin{bmatrix}\sqrt{x^2+y^2}\\ \mathrm{atan2}(-y,-x)-\theta\end{bmatrix}$
	- $H=\begin{bmatrix}\frac x{\sqrt{x^2+y^2}}&\frac y{\sqrt{x^2+y^2}} & 0\\ *&\dagger &-1\end{bmatrix}$
- how to implement EKF
	1. define the state
	2. determine the expressions of $f,h$
	3. compute the Jacobians $F_x=\frac{\partial f}{\partial S},F_u=\frac{\partial f}{\partial U},H=\frac{\partial h}{\partial S}$
	4. we need the covariance matrices $Q,R$
- EKF is a heuristic solution (we are performing linearization)
- initial $\mu,P$ depends on the problem
	- when estimating the initial $P$ (“errors”), we may assume independence
- example: self-calibration for differential drive
	- we cannot measure the distance of the wheels and the radii of the wheels precisely
	- also, there's a noise on the sensor
	- $S=(x,y,\theta,\delta^R,\delta^L,\delta^b)$
		- $\delta$ … calibration parameters
		- real shift of the right wheel = $s^R\cdot \delta^R$
		- real distance of the wheels = $b\cdot\delta^b$
	- $u=(s^R,s^L)$
	- we define $f(S,u)$ using the following expressions (without the lower indices)
		- $x_i=x_{i-1}+\frac{s^R\delta^R_{i-1}+s^L\delta_{i-1}^L}2 \cos\theta_{i-1}$
		- $y_i=y_{i-1}+\frac{s^R\delta^R_{i-1}+s^L\delta_{i-1}^L}2 \sin\theta_{i-1}$
		- $\theta_i=\theta_{i-1}+\frac{s^R\delta^R_{i-1}-s^L\delta_{i-1}^L}{b\delta^b_{i-1}}$
		- for $\delta^R,\delta^L,\delta^b$ it holds that $\delta_i=\delta_{i-1}$
	- we define $h(S)=\sqrt{x^2+y^2}$
	- $F_x=\begin{bmatrix} 1 & 0 & -\delta\rho\sin\theta & \frac{s^R}2\cos\theta & \frac{s^L}2\cos\theta & 0 \\ 0 & 1 & \delta\rho\cos\theta & \frac{s^R}2\sin\theta & \frac{s^L}2\sin\theta & 0 \\ 0 & 0 & 1 & \frac{s^R}{b\delta^b} & \frac{-s^L}{b\delta^b} & ? \\ 0 & 0 & 0 & 1 & 0 & 0 \\ 0&0&0&0&1&0 \\ 0&0&0&0&0&1 \end{bmatrix}$
		- where $\delta\rho=\frac{s^R\delta^R+s^L\delta^L}2$
		- we can write $F_x$ as four blocks: $F_x^R,F^C$, then $O,I$
	- we also compute $F_u$ (six rows, two columns)
		- two blocks: $F_u^R$ (robot) and $O$
	- $H=\begin{bmatrix}\frac x{\sqrt{x^2+y^2}} & \frac y{\sqrt{x^2+y^2}} & 0 & 0&0&0\end{bmatrix}$
		- two blocks: $H^R,O$
	- $Q$ … 2×2 matrix (usually diagonal)
	- $R$ … positive scalar
	- let's consider
		- $P_b=\begin{bmatrix} P^R & O \\ O & P^C\end{bmatrix}$
		- $P^C$ … diagonal matrix with $0.1^2$ on the diagonal
		- upper indices
			- $R$ … robot
			- $C$ … calibration
		- then $\mu$ does not get updated for the three parameters $\delta$
			- because $P_bH^T$ has a zero block there
		- so we need to use $P^{RC}$ instead – like this: $P_b=\begin{bmatrix} P^R & P^{RC} \\ (P^{RC})^T & P^C\end{bmatrix}$
	- we start with $P^{RC}=O$ (zero matrix), we'll show that after some time we get non-zero matrix
		- $P_a=F_xP_bF_x^T+F_uQF_u^T$
		- for the second term, we get three zero blocks so it does not influence $P^{RC}$
		- for the first term, we get $F_xP_bF_x^T=\begin{bmatrix} F_x^RP^RF_x^{RT}+F^CP^CF^{CT} & F^CP^C \\ P^CF^{CT} & P^C\end{bmatrix}$
		- so we get a non-zero correlation
		- to make sure we are calibrating, we should prove that the update of $P$ reduces $P^C$ over time
- cooperative localization
	- …
- SLAM
	- …

### Observability

- the hallway is aligned with X axis, robot moves
	- if the hallway is uniform, I will be lost along the X axis for sure (I cannot estimate X)
	- all the initial state that differ only in the X coordinate are indistinguishable
- let's assume we are always in 2D
- $S=(x,y,\theta)$
- exteroceptive sensors
	- distance from the origin
	- bearing of the origin in the local frame
	- bearing of the robot in the global frame
- $u(t),z(t)$ for $t\in[0,T]$
- suppose we know distance from the origin $z(0)$ and we know the bearing of the origin in the local frame, but we don't know the bearing of the robot in the global frame
	- so $x$ is not observable
		- the initial state of the robot could be anywhere on the circle with the radius $z(0)$
	- but $x^2+y^2$ is observable
- suppose we know the bearing of the robot in the global frame and the traveled distance + the robot only travels on a straight line
	- just by using three measurements of the bearing, we can get the exact position of the robot
	- so the state $S$ is observable
- question: is there such a motion we can perform to find the exact initial state?
- observability rank condition
	- state $S$ with $n$ components
	- can we determine the initial state by performing continuous measurement?
	- we have $n$ unknowns
		- we don't need to find them
		- we just want to say if they are observable or not
	- classical problem … $Ax=b$
		- observable if $\det A \neq 0$
	- or if we know that $g_1(x_1,\dots,x_n)=0,\dots,g_n(x_1,\dots,x_n)=0$
		- inverse function theorem
		- we can find such $x_1,\dots,x_n$ if $\det J\neq 0$
	- $z(t)=h(S(t))$
	- so $z(0)=h(S(0))$
	- there's a theorem that we can transform $z(t)$ and $u(t)$ into functions dependent on the initial state
	- we need continuous description of state
	- we have $s_i=f(s_{i-1},u_i)$ and $z_i=h(s_i)$
	- we need something like $\dot s=f(s,u)$
	- we had $x_i=x_{i-1}+\delta\rho\cos\theta_{i-1}$
		- $x_i-x_{i-1}=\delta\rho\cos\theta_{i-1}$
		- so we get $\dot x=v\cos\theta$
		- $\dot y=v\sin\theta$
		- $\dot\theta=\omega$
	- then $u=(v,\omega)$ … linear speed, angular speed
	- $\dot S=f_0(S)+u_1f_1(S)+\dots+u_mf_m(S)$
	- $\dot{\begin{bmatrix}x\\ y\\ \theta\end{bmatrix}}=\underbrace{\begin{bmatrix}0\\0\\0\end{bmatrix}}_{f_0(S)}+v\underbrace{\begin{bmatrix}\cos\theta \\ \sin\theta \\ 0\end{bmatrix}}_{f_1(S)}+\omega \underbrace{\begin{bmatrix}0\\0\\1\end{bmatrix}}_{f_2(S)}$
	- Lie derivatives
- …
