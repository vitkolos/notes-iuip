# Lecture

- robot = mechatronic system with perception, decision and action capabilities, that can perform in an autonomous way different tasks in the real world
	- multi-purpose
	- autonomous
- sensor = device that measures a physical property and returns a signal of varying complexity
	- exteroception – information from the outside world
	- interoception – information from within the body of a robot
	- proprioception – information from within related to the movement of the body parts
- actuator = device generating a movement, that controls one degree of freedom (rotation, translation)
	- LED is not an actuator :(
	- effector … more complex for manipulation or mobility
- the three Ds: dull, dirty, dangerous (tasks)
- odometric drift – actuators and sensors are not precise, the error accumulates
	- how to solve it
		- use a map (purposes of a map: localization, computing the route to a given goal)
- motion planning
	- feasible plan = takes the capabilities of the robot into account
	- motion strategies can have different forms – it can be a path, a set of procedural instructions
	- for a walking humanoid robot, the plan would be quite complex
- motion planning vs. navigation (obstacle avoidance etc.)
	- motion planning – global map, strategic level
	- obstacle avoidance – local map, tactical level
- workspace
	- physical space where the robot lives, usually $\mathbb R^2$ or $\mathbb R^3$
	- obstacles, free space
	- types of models
		- continuous metric model
			- polygons – their vertices
			- memory complexity proportional to the number of obstacles
		- discrete metric model
			- pixels: free, fully occupied, partially occupied
			- memory complexity proportional to the size of workspace and the resolution
		- topological model
			- nodes and edges
			- we don't care about the geometry – we only capture places and ways to move from one to another
			- the robot needs to be able to localize itself (what is the current “place”) and to get from one place to another according to the edges in the graph
		- hybrid
	- selection criteria: sensors available, precision required, complexity (memory requirements)
- Piano Mover's Problem
	- free flying robot (rigid object) = piano
	- stationary obstacles (fixed rigid objects)
	- the focus is on the geometry, path planning
- with moving obstacles, time becomes very important
	- we need to know (model) the future motions of the obstacles in order to plan the path
- what is the robot is no longer free flying?
	- two classes of kinematic constraints
		- holonomic – restrict the set of possible position (like obstacles)
			- example: limitations of the robotic arm due to its joints etc.
			- to account for the constraints, we only add some virtual obstacles
		- nonholonomic – restrict the set of possible differential motions
			- example: a wheel rolling without slipping on the plane (you should move in a direction perpendicular to the axis of the wheel)
- prehensile manipulation – we grasp an object and manipulate with it
- non-prehensile manipulation – we push or throw an object
- flexible objects → mechanics of deformation
- uncertainty
	- sources: sensors, actuators
	- model error, action error
- human-robot motion
	- main issues
		- safety – we don't want the robot to collide with people
		- acceptability (politeness) – the robot should not interrupt people engaging in a conversation
	- attention-based HRM
		- we don't want to distract people in the museum
- configuration space
- how to address motion planning
	- mobile robot
		- reactive strategy
		- graph search, A\*
		- reinforcement learning
		- robot position … coordinates
	- arm robot
		- vector of joint angles
- **configuration**
	- fundamental tool to address motion planning
	- *set of independent parameters uniquely specifying the position and orientation of every component of a robotic system relative to a fixed coordinate system*
	- usually expressed as a vector of positions/orientations
	- configuration space = space of all the configuration
	- example: polygonal robot which can only translate (no rotation)
		- we pick a reference point $R$
		- $q=(q_x,q_y)$ … configuration (coordinates of $R$)
		- $C=\mathbb R^2$ … configuration space
		- $W=\mathbb R^2$ … workspace
	- example: robot which can also rotate
		- $q=(q_x,q_y,\theta)$
		- $C=\mathbb R^2\times S^1$
			- $S^1$ … $[0,2\pi[$ (to some extent)
				- we could also use $[-\pi,\pi[$ or something similar
	- example: free-flying robot in 3D
		- $q=(q_x,q_y,q_z,\theta_\alpha,\theta_\beta,\theta_\gamma)$
		- Euler angles (roll, pitch, yaw)
	- example: robotic arm with two joints
		- $q=(\theta_1,\theta_2)$
		- $C=S^2$
	- example: mobile robot (car) with an arm with two joints
		- $q=(x,y,\theta,\theta_1,\theta_2)$
- configuration space vs. workspace
	- example: robotic arm with two joints
		- base of the robot can be put anywhere → workspace … $\mathbb R^2$
		- $C=S^2$ is bounded
		- $S^2$ topology = sphere
		- but we cannot uniquely convert the top of the sphere to two angles → we need to use a torus
		- $C=S^1\times S^1$
	- what is the shortest path between two configurations in $S^1\times S^1$?
		- in Cartesian space, it would be easy
		- we need a metric
- configuration space path
	- path $\pi:[0,1]\to C$ … continuous sequence of configurations
	- trajectory … time-parametrized path
- configuration types
	- free, collision, contact
	- contact configurations are interesting if you want to pick up something with a robotic arm
	- image of an obstacle in a $C$ space becomes much more complicated
		- we need to capture the structure of the workspace, compute forbidden regions
	- in the workspace, the robot is a body × in the configuration space, the robot is a point
- example: extensible arm with a joint
	- $q=(x,\theta)$
	- $x\in[1,3]$
	- $\theta\in[0,2\pi[$
	- $C=\mathbb R\times S^1$ … cylinder topology

## Path Planning

- completeness issue
	- complete algorithm: finds a solution if one exists, reports failure if not
	- complexity of complete path planning: strong evidence that it takes time exponential in $d$, the dimension of the configuration space $C$
	- specific complete path planning algorithms have been implemented for $d=$ 2, 3, or 4
	- two complete general purpose path planning algorithms have been proposed, none has been implemented
- algorithms
	- complete … finds a solution
	- heuristic … finds a solution in most cases
	- probabilistic completeness … probability of finding a solution approaches 1 if given enough time
	- resolution completeness … complete for a given resolution level
- usual methods
	- exploring a search graph
	- incrementally building a search tree
- visibility graph
- Voronoï diagram
- cellular decomposition
	- trapezoidal decomposition
		- how to move from one cell to another? we could use the centroids of the shared sides
		- cannot be used if we don't have polygonal obstacles
			- typical problem if the C space is torus
	- approximate cellular decomposition
		- discretize the C space
		- remove the occupied and partially occupied cells
		- problems: narrow passage
	- hierarchical cellular decomposition
		- highly depends on the dimensionality of the C space – the memory requirements grow exponentially
- probabilistic roadmap
	- it's difficult to compute C space obstacles
	- it's easy to check if a configuration collides or not
		- also, we can easily check if a line segment collides or not
	- we randomly sample points, check if they collide and if the lines connecting them collide
	- this way, we form a network
	- the algorithm is probabilistically complete
	- very useful for C space of high dimensionality (like 97 dimensions)
- tree-based methods
	- grid-based methods
		- A*
		- bi-directional search
			- is somehow better
	- configuration-space lattices
	- rapidly-exploring random tree
		- algorithm
			- we have a tree
			- sample a configuration in the whole space
			- find the closest node of the tree
			- extend the tree by $\varepsilon$ distance in the direction of the new configuration (if such path is collision-free)
		- brownian motion explores circle/sphere
			- RRT works better
			- RRT is naturally biased towards large unexplored regions
		- probabilistic completeness
		- we need a metric
- other methods
	- navigation function
		- “feedback motion planning”
		- navigation function should be smooth, should have global minimum at the goal and no other local minima
		- gradient descent
	- potential field
		- obstacle … repulsive field
		- goal … attractive field
		- robot … particle, subject to forces
		- there can be multiple local minima :(
			- how to avoid getting stuck in a local minimum
			- we can use “basin of attraction”
			- or we can try to move randomly out of the basin
	- path deformation
		- start from the original path and deform it until it becomes collision-free
		- ill-suited for dynamic environments
		- space deformation × time deformation
- so far we talked about geometric constraints
- kinematic constraints
	- $F(q,\dot q)=0$
	- holonomic constraint
		- example
			- $\dot x=\dot y$
			- $x=y+c$
			- robot can only move on line $y=x$
		- we just introduce new obstacles in the C space
		- example: robotic hand with glass of water has to be upright – we limit the hand to some angles
	- nonholonomic
		- non integrable
		- example in $R^2\times S^1$
			- $\dot x\sin\theta-\dot y\cos\theta=\theta$
			- “the wheel has to always move in this direction”
		- nonholonomic system: the dimension of the control space is less than the dimension of the configuration space
		- controllability
			- locally controllable system
			- small-time locally controllable system
		- steering
			- no general method
			- we can use circles for a car
		- untractable problem, we need to decouple geometric and kinematic constraints
		- topological property
			- the space we need to maneuver
			- we want to get from the middle of the blue circle to every point in the blue circle
			- to get there, we may need to exist the blue circle but we always stay in the pink circle
		- using topological property
			- we have a geometrically feasible path
			- we find the largest pink circle that does not collide with any obstacles on the path
			- from the size of the pink circle, we compute the blue circle and “tile” the path using blue circles
		- Reeds & Shepp optimal paths
		- steering method – verifying the topological property
		- holonomic path approximation
		- we apply postprocessing to remove weird parts of the path
		- graph-based nonholonomic planner
			- we use PRM, but connect the points using the steering method
		- can we change RRT to use it to plan paths for cars?
			- yes, but the epsilon advancement has to be feasible – so we can use the steering method or choose from all the possible epsilon advancements the closest one to the sampled point

## Obstacle Avoidance

 - path planning
	 - input
		 - robot model (configuration space)
		 - start, goal (configurations)
		 - workspace model (obstacles, …)
	- output – path
- reactive navigation (curve in the C space connecting A and B)
	- robot model
	- local map (sensor data)
	- nominal motion/goal
- bug 1 (Lumelski 86)
	- algorithm
		- robot moves to goal until obstacle
		- fully circumnavigate obstacle
		- circumnavigate again to boundary closest to the goal
		- repeat until goal is reached
	- low memory requirements
	- path can be very long
	- converges to the goal
- bug 2
	- we use a line towards the goal
	- convergency does not directly follow from the algorithm
- VisBug
- potential field
	- handling local minima – random motion
- vector field histogram
	- occupancy probability (in a grid)
- dynamic window
	- translational and rotational velocities
	- takes into account the acceleration capabilities of the robot
- velocity obstacles
	- takes into account moving obstacles
- non linear velocity obstacles
- end-to-end navigation
	- we don't separate perception, localization, planning, and control
	- instead, the robot learns a mapping between sensor data and actions
	- supervised learning – ALVINN
	- reinforcement learning
		- policy learned through trial-and-error
		- training in simulation
		- dynamic programming, monte carlo, Q-learning, SARSA, DDPG, …
	- LLM-based navigation
		- GPT-driver
	- how to combine end-to-end techniques with the more robust ones?
		- safety filters?
- wrap up
	- motion planning
		- global map, off-line, strategic resoning
		- motion optimality
		- convergence to the goal
		- no reactivity
	- reactive & end-to-end navigation
		- local sensor map, on-line, tactical reasoning
		- motion optimality?
		- convergence to the goal?
		- reactivity
	- safety – concern

## Safety

- one of the main motivations for self-driving cars
- “absolute” motion safety for self-driving cars
	- we never collide with any obstacle
- why collisions happen?
	- hardware failures
	- software bugs
	- misunderstanding
	- misreasoning
- we'll focus on misreasoning in dynamic environments
	- can motion safety be guaranteed?
- in dynamic environments
	- we reason about the future
	- we are limited by the decision time
	- appropriate time horizon – how far do we look in the future?
- inevitable collision states (ICS)
	- “I will be in collision in the future no matter what I do”
	- we need to stay away from ICS
	- obstacles are not independent!
	- in general, we need an infinite time horizon
- the time horizon and the decision time are determined by the environment
	- if the time horizon is infinite, we cannot guarantee absolute motion safety
- modeling the future (forbidden regions)
	- deterministic – we know where the obstacles end up
	- conservative – are not sure, so we let the forbidden regions grow
		- problem: if they grow infinitely → no collision-free path in the future (with an infinite time horizon)
	- probabilistic
		- no obstacles in the far future
- passive motion safety
	- should a collision take place, the robot will be at rest
	- now, we don't need an infinite time horizon
	- everybody enforces it → no collision at all

## Kinematics of articulated robots

- Pierre-Brice Wieber, INRIA Grenoble (three lectures)
	- pen and paper, exercises for the exam (quarter of the exam points) clearly labelled
	- not all the theory will be required
- Hans Moravec's paradox
- model predictive control (MPC) × reinforcement learning (RL)
	- both have the same goal
	- RL – we train the model (offline), the we use it
		- approximation
		- sim-to-real gap
	- MPC runs optimization online for the given situation
	- here, we focus on MPC
	- problem with RL
		- we don't know how it behaves in unseen scenarios
		- robots can be dangerous – you need to make sure that you don't kill people on accident
			- we don't know how to achieve safety without physics and mathematics
- three lectures: kinematics, dynamics, advanced topics
- serial manipulator robots × parallel robots
	- serial … series of joints/motions
		- lot of the energy goes into carrying the robot itself
	- parallel – several motors work together to move one part of the robot
		- errors don't add up
		- most of the robot does not move
	- humanoid robots are mostly serial
		- two hands working together → parallel robotics
- first exercise – basic geometry
	- express $P_1,P_2$ ($x,y$ coordinates) as a function of $q_1,q_2$ (angles)
	- $x_1=\cos q_1$
	- $y_1=\sin q_1$
	- $x_2=\cos q_1+\cos q_2$
	- $y_2=\sin q_1+\sin q_2$
- slides on Chamilo
- notation
	- $\dot x=\frac{dx}{dt}$
	- $\dot q=\frac{dq}{dt}$
- let's say $x(t)=\cos q(t)$
	- $\dot x=-\sin(q)\dot q$
- second exercise: write $\dot x_2,\dot y_2$
	- then, express this as a multiplication of a matrix and a vector (Jacobian matrix)
	- how to get $\dot q_1,\dot q_2$ if we know $\dot x_2,\dot y_2$?
		- we need an inverse of the Jacobian matrix
		- fully extended arm → Jacobian matrix is not invertible
			- instantaneous speed can only be up and down
			- intuition: skiing with bent knees
- third exercise: is there an inverse of the Jacobian matrix?
	- if not, why? (when yes, when no?)
		- fully extended, fully flexed
	- 2×2 matrix → determinant = $ad-bc$
	- using sin/cos formulas
- we don't always need to deal with the Cartesian space
	- we don't need the exact location of the ends of the fingertips
- what can we do when we reach a singularity (the matrix is singular)?
	- first approach: throw away one of the rows of the matrix and solve the equation
	- second approach: if we cannot make the two sides of the equation equal, we try to minimize their distance (squared)
		- least squares
		- also, we want to minimize the norm of the solution (regularization, kind of)
		- → Moore-Penrose pseudo-inverse
			- we minimize a quadratic function
			- constrained quadratic program
				- least squares … has infinitely many minimums on a line
					- we want to find a solution on the line
				- least norm … has only one (global) minimum
					- we use Lagrange multipliers to find the constrained minimum (usually different from the global minimum) on the line
	- third approach: perturbation (modify the matrix to make it convertible)
		- does not work well
		- we don't divide by zero but by very small numbers → we get solutions close to infinity
	- Tikhonov regularization (damping)
- kinematics of one rigid body
	- translation, rotation
	- Horner scheme … we can compute polynomial more quickly and more precisely
		- similar approach can be used in kinematics
- priorities for a bus
	- safety deceleration limit
	- collision avoidance
	- schedule
- hierarchy of tasks

## Dynamic Motion Control

- Lyapunov stability
	- continuity of motion (to some extent)
	- is $\dot x=k(x_0-x)$ stable?
	- methods to check stability
		- second method
			- we use some $V(x)$ that is locally continuous positive definite and $\dot V$ is non-positive
				- $V$ is usually related to the energy of the system
				- $V$ … Lyapunov function
			- let's have $V(x)=\frac12\|x-x_0\|^2$
			- $\frac d{dt}\frac12\|x-x_0\|^2=(x-x_0)^T\dot x=-k\|x-x_0\|^2\leq 0$
				- we plugged $\dot x$ in
				- it is $\leq 0$, so it is stable
	- stability does not mean convergence, just not divergence
- spinning objects
	- Newton equation
		- the derivative equation does not hold if the mass changes
	- Euler equation – for rotation
		- the object does not lose mass but its shape is changing (seen from far away)
		- the momentum is constant, the object keeps rotating in the same way – only its shape changes
- dynamics of a robot
	- we're gonna use Gauss' principle of least constraint
	- Lagrangian dynamics
		- $\frac{\partial\mathcal D}{\partial\ddot q}=M(q)\ddot q+N(q,\dot q)\dot q-\mathcal F=0$
	- PD+ control
		- proportional derivative controller + compensation for gravity
			- if we make a small error in the compensation, the system will be stable but with respect to a different position
	- task function approach
		- “does the sensor output we have correspond to the output we want?”
	- idea
		- you don't need a precise model if you can apply corrections
- exam question
	- kinetic energy of a robot
	- $K=\frac12m_1v_1^2+\frac12m_2v_2^2$
	- to get $v$, we need Jacobians
	- we want to get to $K=\frac 12\dot q^T M(q)\dot q$
- minimal coordinates
	- joint positions
	- position and orientation with respect to the environment
- without external forces, you cannot translate
	- but you can rotate
	- also, you cannot walk with zero rotational speed
- contact forces
	- Newton equation – to not fall, we need contact points but their location does not matter
	- Euler equation – location of the contact points matters

## Estimation

- we estimate the state (several physical quantities) of the robot
	- e.g. localization
		- 3 dimensions in 2D (x, y, angle)
		- 6 dimensions in 3D
	- based on measurements (sensors)
	- in general, the sensors don't directly provide the components of the state
	- usually, there is also some noise
- classes of sensors
	- related to the evolution of the state
		- e.g. encoder on the wheels
		- $S_i=f(S_{i-1},u_i)$
			- $S_i$ … state at time $i$
			- $u_i$ … measurement at time $i$
		- *proprioceptive sensor*
	- related only to the current state at a given time
		- $z_i=h(S_i)$
			- $z_i$ … measurement at time $i$
		- *exteroceptive sensor*
- synchronous drive: free-moving robot with three synchronous wheels (just like a single moving wheel, it can rotate and move forwards/backwards)
	- $u_i=(\delta\rho_i,\delta\theta_i)$
	- $S=(x,y,\theta)$
	- actions of rotation and move are not commutative w.r.t. position
		- we end up at a different position if we first move and then rotate
		- but we can assume that the sampling is very fast
	- we can define $f$ like this
		- $x_i=x_{i-1}+\delta\rho_{i-1}\cos\theta_{i-1}$
		- $y_i=y_{i-1}+\delta\rho_{i-1}\sin\theta_{i-1}$
		- $\theta_i=\theta_{i-1}+\delta\theta_i$
- differential drive
	- $u_i=(\alpha^R_i,\alpha^L_i)$
	- $r^R,r^L$ … radii of wheels
	- shift: $s^R=r^R\alpha^R$ (similar for $s^L$)
	- $\delta\rho=\frac{s^R+s^L}2$
	- $\delta\theta=\frac{s^R-s^L}{b}$
- examples of $h$
	- if we measure the distance from origin
		- $z=h(S)=\sqrt{x^2+y^2}$
- we try to find (and update) a probability distribution
	- we start with a uniform distribution
	- how to update it to reflect the new measurements?

### Bayes filter

- total probability
	- $P(A)=\sum_B P(A,B)$
	- $P(A\mid C)=\int dB\;P(A\mid B,C)P(B\mid C)$
- Bayes law
	- $P(A\mid B)=\frac{P(B\mid A)P(A)}{P(B)}$
	- $P(A\mid B,C)=\frac{P(B\mid A,C)P(A\mid C)}{P(B\mid C)}$
- $U_i=[u_0,u_1,\dots,u_{i-1},u_i]$
- $Z_i=[z_0,z_1,\dots,z_{i-1},z_i]$
- we start with $P(S_{i-1}\mid U_{i-1}Z_{i-1})$
- *action* leads to $P(S_{i}\mid U_{i}Z_{i-1})$
	- it adds $u_i$
- *perception* leads to $P(S_{i}\mid U_{i}Z_{i})$
	- it adds $z_i$
- clearly $P(S_i\mid U_iZ_{i-1})=\int dS_{i-1}\;P(S_i\mid S_{i-1},U_iZ_{i-1})P(S_{i-1}\mid U_iZ_{i-1})$
	- where $P(S_{i-1}\mid U_iZ_{i-1})=P(S_{i-1}\mid U_{i-1}Z_{i-1})$ as the previous state is independent on the next measurement
	- by Markov assumption, $P(S_i\mid S_{i-1},U_iZ_{i-1})=P(S_i\mid S_{i-1},u_i)$
		- it's an approximation (in reality, for example, the error of the sensor may be influenced by the past measurements)
	- so we get $P(S_i\mid U_i Z_{i-1})=\int dS_{i-1}\;P(S_i\mid S_{i-1},u_i)P(S_{i-1}\mid U_{i-1}Z_{i-1})$
- $P(S_i\mid z_i,U_i Z_{i-1})=\frac{P(z_i\mid S_i,U_iZ_{i-1})P(S_i\mid U_iZ_{i-1})}{P(z_i\mid U_iZ_{i-1})}$
	- so $P(S_i\mid U_i Z_{i})=\eta P(z_i\mid S_i) P(S_i\mid U_i Z_{i-1})$
	- $\eta$ … normalization factor
- example: exteroceptive sensor
	- $h(x)=L-x=h(S)$
	- let's consider Gaussian
	- $z^m=N(z,\sigma^2)$
		- $z^m$ … measured
		- $z$ … true
	- $z^m=N(L-x,\sigma^2)$
	- $P(z\mid S)=N(L-x,\sigma^2)$
- example: proprioceptive sensor
	- $x_i=x_{i-1}+R\alpha$
	- $\alpha=N(\alpha^m,\sigma_\alpha^2)$
	- $x_i=N(x_{i-1}+R\alpha^m,R^2\sigma_\alpha^2)$
- in reality: trade-off between precision and computational cost (time)
- example
	- we define initial $P(L)$
		- $P(3)=0.2$
		- $P(4)=P(8)=0.4$
		- otherwise, $P(L)=0$
	- $P(L'\mid u)=\sum_L P(L'\mid L,u)P(L)$
		- $u$ … observed shift
		- we can define $P(L'\mid L,u)=\begin{cases}1&\text{if }L'=L+u\\0&\text{otherwise}\end{cases}$
		- more realistic definition
			- 0.8 if $L'=L+u$
			- 0.1 if $L'=L+u\pm 1$
	- $P(L'\mid z)=\eta P(z\mid L')P(L')$
		- again, we have $P(z\mid L')$ defined somehow
		- we also have $P(L')$
		- we need to get $\eta$ by computing $P(z\mid L)P(L)$ for every $L$ and making sure $P(L'\mid z)$ sums to 1
			- in other words, $\eta=\frac1{\sum_{L} P(z\mid L)P(L)}$
- sometimes, we can assume that the functions are linear and the (error) distributions are Gaussian
	- then, everything is Gaussian (we get convolution of two Gaussians which is a Gaussian)
	- we only need mean (vector) and variance (covariance matrix – symmetric and positive semi-definite)
	- → Kalman filter
	- if the assumptions don't hold, we may use a heuristic solution (extended Kalman filter)
- reminder (simplified)
	- $P(S_i\mid U_i)=\int dS_{i-1}\; P(S_i\mid S_{i-1}u_i)P(S_{i-1})$ … action
	- $P(S_i\mid Z_i)=\eta P(z_i\mid S_i)P(S_i)$ … perception
- let's say $x$ is a random variable with Gaussian distribution
	- $x=N(\mu,\sigma^2)$
	- $P(x)=\frac1{\sqrt{2\pi\sigma^2}}\exp(-\frac12\frac{(x-\mu)^2}{\sigma^2})$
	- mean value $\braket{x}=\int_{-\infty}^\infty dx\; xP(x)$
	- variance $\braket{(x-\braket{x})^2}$
- let's consider $P(x_1,x_2)$
	- covariance matrix
- vector case
	- mean vector $\mu$
	- covariance matrix $P$
	- before … $\mu_b,P_b$
	- after … $\mu_a,P_a$
- we need to approximate a non-linear function with a linear function
	- $g(x)\approx g(x_0)+\frac{dg}{dx}\bigg\vert_{x_0}(x-x_0)$
	- so $f(S_{i-1},U_i)=f(\mu_b,u^m)+\frac{\partial f}{\partial S}\bigg\vert_{\mu_b,u^m} (S_{i-1}-\mu_b)+\frac{\partial f}{\partial U}\bigg\vert_{\mu_b,u^m} (U_i-u^m)$
- extended Kalman filter (EKF) prediction
	- $\mu_a=f(\mu_b,u^m)$
	- $P_a=F_xP_bF_x^T+F_uQF_u^T$
	- $Q$ … covariance of the noise of the measurement
- example: wheel
	- $x_i=x_{i-1}+R\alpha_i$
	- $f(S,u)=S+Ru$
	- $\mu_a=\mu_b+R\alpha^m$
	- $F_x=1$
	- $F_u=R$
	- $P_a=\sigma^2_a=\sigma^2_b+R^2\sigma_q^2$
- example: differential drive
	- we have
		- $\delta\rho=\frac{s^R+s^L}2$
		- $\delta\theta=\frac{s^R-s^L}{b}$
		- $f(S,u)=\begin{bmatrix}x+\delta\rho\cos\theta\\ y+\delta\rho\sin\theta \\ \theta+\delta\theta\end{bmatrix}$
		- so $f(S,u)=\begin{bmatrix}x+\frac{s^R+s^L}2\cos\theta\\ y+\frac{s^R+s^L}2\sin\theta \\ \theta+\frac{s^R-s^L}{b}\end{bmatrix}$
	- $F_x$ … Jacobian of $f$ w.r.t. $(x,y,\theta)$
	- $F_u$ … Jacobian of $f$ w.r.t. $(s^R,s^L)$
	- $Q$ … covariance for $(s^R,s^L)$
- after an exteroceptive measurement
	- $\mu_a=\mu_b+P_bH^T[HPH^T+R]^{-1}(z^m-h(\mu_b))$
	- $P_a=P_b-P_bH^T[HP_bH^T+R]^{-1}HP_b$
	- $R$ … noise on the vector $z$ (measurement)
	- $h(\mu_b)$ … predicted observation
	- $z^m-h(\mu_b)$ … innovation