# Lecture

- challenges in AI (or computer science in general): scale, autonomy, delegation, cooperation
- MAS … field of AI interested in designing systems of autonomous interacting entities
- course overview
	- general introduction
	- agent interactions: communication, game theory
	- distributed problem solving
	- agent-based modelling and simulation (course, case study, tutorials)
	- human factors in MAS
	- collective decisions in MAS: theory of social choice
- agent … perceiving and acting
- autonomy (but autonomous agent still could decide randomly)
- rational agent
- another definition: agent
	- physical or virtual entity, has its own resources, possibly a representation of its environment
	- acts autonomously to satisfy some tendencies (goals) … proactive
	- while taking into account its limited resources, perceptions etc. … reactive
- physical vs. communicative actions
- agent architectures
	- simple reactive agent
	- agent with an internal state
	- goal-based agent
	- utility-based agent
		- in case of conflicting goals or uncertain effects
- performance vs. utility
- 5 properties of environments
	- accessibility
		- are all the relevant aspects of the environment instantly available to the agent? → we don't need to maintain an internal state
	- determinism
		- is the next state completely determined by the current state and the actions selected by the agents?
	- accessible + deterministic → no uncertainty
	- episodic vs. sequential environment
		- do future states depend on past actions? → sequential environment
		- episodic environments are simpler, agents can make reactive decisions and do not need to remember the history (example: old chatbots)
	- static vs. dynamic environment
		- dynamic environment can change during deliberation → we need to think fast (example: autonomous car)
		- semi-dynamic environment does not change during deliberation but the passage of time is important (e.g. performance score)
		- static environment does not change during deliberation, time does not matter
	- discrete vs. continuous
		- discrete environment – limited number of distinct, clearly defined percepts and actions
- examples
	- chess: accessible, deterministic, sequential, static or semi-dynamic (with a clock), discrete
	- poker: inaccessible, indeterministic, sequential
	- taxi driving: inaccessible, indeterministic, sequential, dynamic, continuous
- finding a balance between reactivity and proactivity (so that we don't get distracted)
- applications
	- distributed problem solving
	- agent-based modelling and simulation
- Gama, Netlogo
- reactive agent vs. cognitive agent
	- cognitive agent can reason about the environment
	- reactive agent can only move randomly and perform some reactive actions
- practical reasoning
	- action-oriented reasoning = process of deciding what to do (not what to believe or what is true)
	- human practical reasoning
		- deliberation – what state of affairs I want to achieve?
		- means-end reasoning – how do I get there?
	- intentions in practical reasoning
		- effort and resources put into achieving intention
		- no conflict: intentions serve as a filter for adopting new intentions
		- success tracking + persistance after failure
		- possible – intentions are believed to be possible
		- feasibility – not believed to never be reached
		- …
	- Bratman's theory
- BDI architecture
	- beliefs
		- representation of the world
		- possible incorrect and incomplete
	- desires
		- our goal
	- intentions
		- how to achieve the goal
		- intentions lead to actions
		- in a dynamic environment, we need to reconsider the intentions
			- we need to find a balance, we cannot be to indecisive
			- intention reconsideration – 3 commitment strategies
	- BDI goal-plan diagram (tree)
		- list of all plans we can use to achieve the goal
		- each plan consists of several atomic actions
		- example: gold miners
			- goal: earn money
			- plans: sell gold | other job
			- how to sell gold: have gold & go to market & sell
			- how to have gold: steal gold | pick gold
		- on every level of the tree, we switch between AND and OR
	- BDI pros & cons
		- grounded in philosophy, formal logic
		- high level of abstraction, captures folk psychology
		- explains why an agent does something
		- extensible, flexible, robust, failure recovery
		- dedicated programming frameworks (example: GAMA)
		- but complex, may be computationally slow
- reflex architecture
	- stimulus-action rules
	- directly triggered by stimuli in the environment
	- less complex than symbolic AI
	- example: ants
		- go back to nest = follow pheromones the other way
	- finite-state machines
	- subsumption architecture
		- hierarchy of competence modules (CM)
		- each module is responsible for a concrete, clearly defined, simple task
		- all modules operate in parallel
		- rather simple rule-like structure
		- lower layers can inhibit higher layers
			- by suppressing input signals or inhibiting output signals
	- example: Mars explorer (Steels)
		- highest priority: obstacle avoidance
		- drop carried samples at base
		- return to base when carrying sample
		- collect found samples
		- lowest priority: exploration
	- how can reactive agent locate the base?
		- gradient field – the base emits radio signal
	- how can robots communicate together?
		- we want to tell the other robots where the clusters are
		- we use “feromones” – stigmergy (indirect communication through environment)
			- robots drop radioactive crumbs
			- other robots need to pick them to make the trace “fade away”
		- https://nausikaa.net/wp-content/uploads/2022/09/steels-mars-explorer-02.html
	- for reactive agents, the environment has to be accessible
- hybrid architectures
	- reactive and deliberative layers
		- obstacle avoidance can be reactive
	- how to handle interaction between layers?

## Game Theory

- applications
	- biology – survival of the fittest (winners)
	- political sciences – military strategy, Cold War
- typology of games
	- zero-sum games
	- cooperative vs. competitive
	- simultaneous vs. sequential
	- information available – complete information, incomplete information (Bayesian games), imperfect information
- examples
	- shifumi (rock-paper-scissors)
	- chicken game
- notation
	- players $i,j$
	- results $W=\set{w_1,\dots,w_n}$
- agents maximize utility
	- absolute values of utility does not convey much meaning, we are more interested in relative comparison (which action has more utility for the agent)
- simplified environment model
	- possible actions $Ac=\set{C,D}$
		- cooperate $(C)$, defect $(D)$
	- the environment is…
		- sensitive – if each combination of actions leads to a different result
		- insensitive
		- controlled – if one player can influence the result
- representation
	- extensive form – decision tree
	- strategic form – matrix
- pure or mixed strategy
- equilibria
	- Nash equilibrium
	- Bayesian equilibrium
- dominant strategy
- Pareto optimality
- social vs. individual benefit
- prisoners' dilemma
	- happens in every situation where $T\gt R\gt P\gt S$
	- $T$ … temptation (successful betrayal)
	- $R$ … reward (we both cooperated)
	- $P$ … punishment
	- $S$ … sucker (I was betrayed)
- how can we establish cooperation in multi-agent systems?
	- iterated prisoners' dilemma
	- Axelrod's tournament
- tragedy of the commons, free riders
- humans are not always economically rational

## Communication

- Shannon
- Berlo
- types
	- point to point × broadcast
	- broker
	- propagation in environment
- meaning – intentional × incident
- 7 steps
	- speaker
		- intention – what information is the speaker trying to communicate
		- generation – generate the message
		- synthesis – send the message (say it…)
	- hearer
		- perception – receive the signal
		- analysis – infer possible meanings
		- disambiguation – try to choose the most probable meaning
		- incorporation – decide to believe the communicated information (or not)
- communication problems
	- technical – message does not arrive at all
	- semantic – hearer does not understand the meaning
	- efficiency – message does not have the intended effect (the hearer chooses not to believe it…)
- misunderstading, potential meanings
	- M1 … original intention (meaning)
	- M2 … meaning that the hearer infers
	- M3 … what the speaker believes that the hearer inferred
- speech acts theory: Austin
	- locutionary act – utterance
	- illocutionary act – intent
	- perlocutionary act – result
- Searle – categories of illocutionary acts
	- assertives
	- commissives
	- directives
	- declaratives
	- expressives
- Vanderveken
	- decomposition into illocutionary force and propositional content
	- success and satisfaction conditions
		- success if the hearer recognizes the intention
		- satisfaction if the speaker's intention is achieved
- we need to know the preconditions and the effects of each speech act
	- we also need boolean conditions to see if a speech act is successful and/or satisfied
- human languages are ambiguous
	- agents use interaction languages
- mentalist(ic) approach
	- based on beliefs
	- FIPA-ACL
	- some strong assumptions/hypotheses
- social approach
	- based on commitment
	- commitments are public
	- are there two contradictory commitments?
- public approach – based on grounding
- deontic approach – based on norms
- interaction protocols
	- shown on KQML
		- direct (point to point)
		- through a matchmaker
		- through a broker
		- through a feeder
	- example: typical request protocol
		- request → accept, refuse, or modify
		- accept → inform-done or inform-failure
		- modify → accept, refuse, or modfiy
	- contract net
		- “I need help for a task”
		- 5 stages
		- bidding, contracts
	- dependence based coalition (DBC), social reasoning
- programming communication
	- keyword-based chatbots
	- logical programming
	- LLMs
- planning speech acts in logical programming
- simulating communication
	- with neighbours vs. with acquiantances

## Modelling

- agent-based modelling and simulation
	- model – simplified abstraction of reality
	- macro patterns emerge from individual decisions
- 7 goals of simulation (Axelrod)
	- prediction – e.g. weather
	- task performance – we want to mimic a human performing the task
	- training – e.g. flight simulator
	- entertainment – imaginary virtual world, for amusement
	- education – users can learn what happens if they do *this* or *that* in the simulation (or how does a volcano work)
	- proof – prove existence/conjecture
	- discovery – discover new knowledge
- social simulation
	- model should be valid (faithful to reality)
- questions to ask before building a model
- simulator – inputs, outputs, what we show
- NetLogo, GAMA
- Game of Life
- Schelling's segregation model
- traffic simulation
- urban planning
	- acteur project, multi-level decision-making
		- strategical – establish list of destinations and try to reach them
		- tactical – adjust plans to implement strategy
			- ordinary situation – adjust to traffic, choose best trajectory, less populated roads, …
			- extraordinary situation – escaper (flee danger), bystander, random wanderer, road runner (less congested), sheep (follow crowd), …
		- operational
	- HIANIC project
		- shared space (cars, pedestrians, bikes)
		- autonomous car navigation
	- Switch project
		- car → bike?
		- 4 mobility modes (walk, bike, bus, car)
		- 6 criteria (comfort, ecology, price, simplicity, safety, time)
			- every agent has priorities
		- decision model with habits
			- with some probability, we rationally reevaluate (if the context has changed – price of gas went up…)
			- otherwise, we stick to our habit
- evacuation modelling, crisis management
	- evacuation – zigzag stairs may be better
	- flood risk management, communication
	- epidemics
	- earthquake
		- Solace – testing the role of social attachment
	- you need realistic cognitive agents
		- take human factors into account
- not all models require the same level of realism
	- entertainment models do not have to be that much realistic
- human factors
	- emotions, empathy, mood, personality
	- trust, moral values, ethics
	- cognitive biases
	- motivation, engagement
	- …
- we need to simulate emotions
	- BDI logical model of emotions
	- book: The Cognitive Structure of Emotions
	- example: distress … agent believes that $\varphi$, but desires $\neg\varphi$
- biases – confirmation bias, …

### Modelling COVID-19

- initially, too many unknowns
- mathematical models
	- people in 3 compartments
		- susceptibles
		- infected
		- recovered
	- parameters
		- $\mu$ … birth/death rate (supposed equal)
		- $\beta$ … contamination rate
		- $\gamma$ … recovery rate
- agent-based models
	- agents can be heterogenous (individual attributes, individual choices)
	- more detailed, better explainibility
	- slower, more complex
	- need individual behaviour data
- data collection
	- place of death
		- people dying in hospitals (in cities), residence address not always available
		- leads to overestimating the gravity of the situation
	- mortality = deaths / cases
		- how to count the deaths? (what if covid was probably not the real cause of death?)
		- how to count the cases? (there are asymptomatic cases…)
- CovPrehension project
	- modelling the spread
		- simplified, 1 contact leads to infection
		- we can calibrate the model based on the reproduction rate
		- we can introduce physical distancing – but in reality it's not always feasible
		- some people cannot / don't want to respect distancing
	- one model not enough to make important political decisions
	- collective immunity
	- who should be tested first?
		- testing symptomatic people is not enough to estimate the number of infected people
	- designing models
		- make your hypotheses clear
		- choose useful attributes, keep agents simple
		- choose a limited number of parameters, should have a visible impact on the output
		- output indicators should be measurable from the model and useful to answer the question

## Agent Control

- basic types
	- procedural – limited
	- learned – needs data, prone to biases
	- control by planning – goal oriented behavior, BDI architecture
- difficulties of planning
	- environment – dynamic, partially observable, continuous
	- perception errors
	- goals – …
	- actions
	- other agents
- classical planning problem
	- many simplifying assumptions
	- …
- model of the problem – we need a formal description of all the following elements
	- initial state
	- list of goals
	- set of actions – with their preconditions and effects
- one approach: situation calculus
	- basic elements
		- actions
		- fluents – describe the state of the world
		- situations – sequence of (past) actions
	- domain then consists of
		- world state descriptions (fluents)
		- actions (one precondition axiom per action + effect axioms)
		- successor state axioms (one per fluent; how fluents change over time)
	- how situations work
		- let's say we are in situation $S$
		- then $S'=\mathrm{Do}(\mathrm{action}(\dots),S)$ is the situation after performing *action*
		- so the situations store the history
	- action preconditions and effects
		- *Poss*
		- block world example of precondition: Poss(move(x,y,z),S) <-> clear(x,S) & on(x,y,S) & clear(z,S)
	- frame problem
		- successor state axioms solve it
- definition: plan
	- set of plan steps
	- set of ordering constraints (timing of steps) – what needs to happen before what; total or partial order
	- set of variables
	- set of causal links between steps
- several types of plans: linear, non-linear, hierarchical
- examples: recipe, itinerary, hanoi towers
- planning algorithms
	- properties: soundness (produces only correct solutions), completeness (produces all existing solutions), optimality (finds the best solution first), speed
	- we can use graph search algorithms: DFS (possible endless loop if tree-search used on a graph), BFS, A\*
		- *expand*, *insert*
		- forward chaining – what can we do at this point?
		- backward chaining – what can lead us to our goal?
	- linear planning
		- means-end analysis – tries to reduce the difference between the current state and the goal
		- STRIPS – implements means-end analysis
		- Sussman anomaly – if we divide the goal (conjuction) into subgoals, we may get suboptimal plans
		- linear plan = sequence of actions
		- linear planning – summary
			- state space
			- operators – transitions between states
			- test function (is goal reached?)
			- path cost (how many steps)
			- progressive × regressive (forward or backward chaining)
		- advantages
			- reduced search space – goals solved one at a time
				- advantageous if goals are independent (but they may often conflict!)
			- sound – only finds correct plans
		- disadvantages
			- may produce suboptimal solutions
			- incomplete
	- non-linear planning
		- considers all goals at the same time
		- more complex
		- may be parallelized