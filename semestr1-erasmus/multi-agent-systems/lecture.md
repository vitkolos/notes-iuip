# Lecture

- challenges in AI (or computer science in general): scale, autonomy, delegation, cooperation
- MAS … field of AI interested in designing systems of autonomous interacting entities
- course overview
	- general introduction
	- agent interactions: communication, game theory
	- distributed problem solving
	- agent-based modelling and simulation (course, case study, tutorials)
	- human factors in MAS
	- collective decisions in MAS: theory of social choice
- agent … perceiving and acting
- autonomy (but autonomous agent still could decide randomly)
- rational agent
- another definition: agent
	- physical or virtual entity, has its own resources, possibly a representation of its environment
	- acts autonomously to satisfy some tendencies (goals) … proactive
	- while taking into account its limited resources, perceptions etc. … reactive
- physical vs. communicative actions
- agent architectures
	- simple reactive agent
	- agent with an internal state
	- goal-based agent
	- utility-based agent
		- in case of conflicting goals or uncertain effects
- performance vs. utility
- properties of environments
	- accessibility
		- are all the relevant aspects of the environment instantly available to the agent? → we don't need to maintain an internal state
	- determinism
		- is the next state completely determined by the current state and the actions selected by the agents?
	- accessible + deterministic → no uncertainty
	- episodic vs. sequential environment
		- do future states depend on past actions? → sequential environment
		- episodic environments are simpler, agents can make reactive decisions and do not need to remember the history (example: old chatbots)
	- static vs. dynamic environment
		- dynamic environment can change during deliberation → we need to think fast (example: autonomous car)
		- semi-dynamic environment does not change during deliberation but the passage of time is important (e.g. performance score)
		- static environment does not change during deliberation, time does not matter
	- discrete vs. continuous
		- discrete environment – limited number of distinct, clearly defined percepts and actions
- examples
	- chess: accessible, deterministic, sequential, static or semi-dynamic (with a clock), discrete
	- poker: inaccessible, indeterministic, sequential
	- taxi driving: inaccessible, indeterministic, sequential, dynamic, continuous
- finding a balance between reactivity and proactivity (so that we don't get distracted)
- applications
	- distributed problem solving
	- agent-based modelling and simulation
- Gama, Netlogo
- reactive agent vs. cognitive agent
	- cognitive agent can reason about the environment
	- reactive agent can only move randomly and perform some reactive actions
- practical reasoning
	- action-oriented reasoning = process of deciding what to do (not what to believe or what is true)
	- human practical reasoning
		- deliberation – what state of affairs I want to achieve?
		- means-end reasoning – how do I get there?
	- intentions in practical reasoning
		- effort and resources put into achieving intention
		- no conflict: intentions serve as a filter for adopting new intentions
		- success tracking + persistance after failure
		- possible – intentions are believed to be possible
		- feasibility – not believed to never be reached
		- …
	- Bratman's theory
- BDI architecture
	- beliefs
		- representation of the world
		- possible incorrect and incomplete
	- desires
		- our goal
	- intentions
		- how to achieve the goal
		- intentions lead to actions
		- in a dynamic environment, we need to reconsider the intentions
			- we need to find a balance, we cannot be to indecisive
			- intention reconsideration – 3 commitment strategies
	- BDI goal-plan diagram (tree)
		- list of all plans we can use to achieve the goal
		- each plan consists of several atomic actions
		- example: gold miners
			- goal: earn money
			- plans: sell gold | other job
			- how to sell gold: have gold & go to market & sell
			- how to have gold: steal gold | pick gold
		- on every level of the tree, we switch between AND and OR
	- BDI pros & cons
		- grounded in philosophy, formal logic
		- high level of abstraction, captures folk psychology
		- explains why an agent does something
		- extensible, flexible, robust, failure recovery
		- dedicated programming frameworks (example: GAMA)
		- but complex, may be computationally slow
- reflex architecture
	- stimulus-action rules
	- directly triggered by stimuli in the environment
	- less complex than symbolic AI
	- example: ants
		- go back to nest = follow pheromones the other way
	- finite-state machines
	- subsumption architecture
		- hierarchy of competence modules (CM)
		- each module is responsible for a concrete, clearly defined, simple task
		- all modules operate in parallel
		- rather simple rule-like structure
		- lower layers can inhibit higher layers
			- by suppressing input signals or inhibiting output signals
	- example: Mars explorer
		- highest priority: obstacle avoidance
		- drop carried samples at base
		- return to base when carrying sample
		- collect found samples
		- lowest priority: exploration
	- how can reactive agent locate the base?
		- gradient field – the base emits radio signal
	- how can robots communicate together?
		- we want to tell the other robots where the clusters are
		- we use “feromones” – stigmergy (indirect communication through environment)
			- robots drop radioactive crumbs
			- other robots need to pick them to make the trace “fade away”
		- https://nausikaa.net/wp-content/uploads/2022/09/steels-mars-explorer-02.html
	- for reactive agents, the environment has to be accessible
- hybrid architectures
	- reactive and deliberative layers
		- obstacle avoidance can be reactive
	- how to handle interaction between layers?

## Game Theory

- applications
	- biology – survival of the fittest (winners)
	- political sciences – military strategy, Cold War
- typology of games
	- zero-sum games
	- cooperative vs. competitive
	- simultaneous vs. sequential
	- information available – complete information, incomplete information (Bayesian games), imperfect information
- examples
	- shifumi (rock-paper-scissors)
	- chicken game
- notation
	- players $i,j$
	- results $W=\set{w_1,\dots,w_n}$
- agents maximize utility
	- absolute values of utility does not convey much meaning, we are more interested in relative comparison (which action has more utility for the agent)
- simplified environment model
	- possible actions $Ac=\set{C,D}$
		- cooperate $(C)$, defect $(D)$
	- the environment is…
		- sensitive – if each combination of actions leads to a different result
		- insensitive
		- controlled – if one player can influence the result
- representation
	- extensive form – decision tree
	- strategic form – matrix
- pure or mixed strategy
- equilibria
	- Nash equilibrium
	- Bayesian equilibrium
- dominant strategy
- Pareto optimality
- social vs. individual benefit
- prisoners' dilemma
	- happens in every situation where $T\gt R\gt P\gt S$
	- $T$ … temptation (successful betrayal)
	- $R$ … reward (we both cooperated)
	- $P$ … punishment
	- $S$ … sucker (I was betrayed)
- how can we establish cooperation in multi-agent systems?
	- iterated prisoners' dilemma
	- Axelrod's tournament
- tragedy of the commons, free riders
- humans are not always economically rational

## Communication

- Shannon
- Berlo
- types
	- point to point × broadcast
	- broker
	- propagation in environment
- meaning – intentional × incident
- 7 steps
	- speaker
		- intention – what information is the speaker trying to communicate
		- generation – generate the message
		- synthesis – send the message (say it…)
	- hearer
		- perception – receive the signal
		- analysis – infer possible meanings
		- disambiguation – try to choose the most probable meaning
		- incorporation – decide to believe the communicated information (or not)
- communication problems
	- technical – message does not arrive at all
	- semantic – hearer does not understand the meaning
	- efficiency – message does not have the intended effect (the hearer chooses not to believe it…)
- misunderstading, potential meanings
	- M1 … original intention (meaning)
	- M2 … meaning that the hearer infers
	- M3 … what the speaker believes that the hearer inferred
- speech acts theory: Austin
	- locutionary act – utterance
	- illocutionary act – intent
	- perlocutionary act – result
- Searle – categories of illocutionary acts
	- assertives
	- commissives
	- directives
	- declaratives
	- expressives
- Vanderveken
	- decomposition into illocutionary force and propositional content
	- success and satisfaction conditions
		- success if the hearer recognizes the intention
		- satisfaction if the speaker's intention is achieved
- we need to know the preconditions and the effects of each speech act
	- we also need boolean conditions to see if a speech act is successful and/or satisfied
- human languages are ambiguous
	- agents use interaction languages
- mentalist(ic) approach
	- based on beliefs
	- FIPA-ACL
	- some strong assumptions/hypotheses
- social approach
	- based on commitment
	- commitments are public
	- are there two contradictory commitments?
- public approach – based on grounding
- deontic approach – based on norms
- interaction protocols
	- shown on KQML
		- direct (point to point)
		- through a matchmaker
		- through a broker
		- through a feeder
	- example: typical request protocol
		- request → accept, refuse, or modify
		- accept → inform-done or inform-failure
		- modify → accept, refuse, or modfiy
	- contract net
		- “I need help for a task”
		- 5 stages
		- bidding, contracts
	- dependence based coalition (DBC), social reasoning
- programming communication
	- keyword-based chatbots
	- logical programming
	- LLMs
- planning speech acts in logical programming
- simulating communication
	- with neighbours vs. with acquiantances

## Modelling

- agent-based modelling and simulation
	- model – simplified abstraction of reality
	- macro patterns emerge from individual decisions
- 7 goals of simulation (Axelrod)
	- prediction – e.g. weather
	- task performance – we want to mimic a human performing the task
	- training – e.g. flight simulator
	- entertainment – imaginary virtual world, for amusement
	- education – users can learn what happens if they do *this* or *that* in the simulation
	- proof – prove existence/conjecture
	- discovery – discover new knowledge
- social simulation
	- model should be valid (faithful to reality)
- questions to ask before building a model
- simulator – inputs, outputs, what we show
- NetLogo, GAMA
- Game of Life
- Schelling's segregation model
- traffic simulation
- urban planning
	- acteur project, multi-level decision-making
		- strategical – establish list of destinations and try to reach them
		- tactical – adjust plans to implement strategy
			- ordinary situation – adjust to traffic, choose best trajectory, less populated roads, …
			- extraordinary situation – escaper (flee danger), bystander, random wanderer, road runner (less congested), sheep (follow crowd), …
		- operational
	- HIANIC project
		- shared space (cars, pedestrians, bikes)
		- autonomous car navigation
	- Switch project
		- car → bike?
		- 4 mobility modes (walk, bike, bus, car)
		- 6 criteria (comfort, ecology, price, simplicity, safety, time)
			- every agent has priorities
		- decision model with habits
			- with some probability, we rationally reevaluate (if the context has changed – price of gas went up…)
			- otherwise, we stick to our habit
- evacuation modelling, crisis management
	- evacuation – zigzag stairs may be better
	- flood risk management, communication
	- epidemics
	- earthquake
		- Solace – testing the role of social attachment
	- you need realistic cognitive agents
		- take human factors into account
- not all models require the same level of realism
	- entertainment models do not have to be that much realistic
- human factors
	- emotions, empathy, mood, personality
	- trust, moral values, ethics
	- cognitive biases
	- motivation, engagement